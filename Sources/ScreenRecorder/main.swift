import Foundation
import ScreenCaptureKit
@preconcurrency import AVFoundation
import AppKit

// éŸ³é¢‘è®¾å¤‡åˆ‡æ¢åŠŸèƒ½
func switchAudioOutput(to deviceName: String) {
    let task = Process()
    task.executableURL = URL(fileURLWithPath: "/opt/homebrew/bin/SwitchAudioSource")
    task.arguments = ["-s", deviceName]
    do {
        try task.run()
        task.waitUntilExit()
        print("âœ… åˆ‡æ¢éŸ³é¢‘è¾“å‡ºè®¾å¤‡åˆ°ï¼š\(deviceName)")
    } catch {
        print("âš ï¸ åˆ‡æ¢éŸ³é¢‘è¾“å‡ºè®¾å¤‡å¤±è´¥: \(error)")
    }
}

@main
struct ScreenRecorder {
    static func main() async {
        if #available(macOS 12.3, *) {
            // è§£æå‘½ä»¤è¡Œå‚æ•°
            let args = CommandLine.arguments
            // ç¬¬1å‚æ•°ï¼šæ—¶é•¿ï¼Œæ¯«ç§’ï¼Œé»˜è®¤10000
            let durationMs = (args.count > 1) ? Int(args[1]) ?? 10000 : 10000
            // ç¬¬2å‚æ•°ï¼šè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ç©ºï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ screenRecording.mov
            let outputPath = (args.count > 2) ? args[2] : nil
            // ç¬¬3å‚æ•°ï¼šæ˜¯å¦æ•´å±å½•åˆ¶ï¼Œä¼  "full" åˆ™ä¸ºæ•´å±ï¼Œé»˜è®¤ç«–å±è£å‰ª
            let fullScreen = (args.count > 3) ? (args[3].lowercased() == "full") : false
            
            await record(durationMs: durationMs, outputPath: outputPath, fullScreen: fullScreen)
        } else {
            print("âŒ å½“å‰ç³»ç»Ÿç‰ˆæœ¬ä¸æ”¯æŒ ScreenCaptureKitï¼ˆéœ€è¦ macOS 12.3+ï¼‰")
        }
    }

    @available(macOS 12.3, *)
    static func record(durationMs: Int, outputPath: String?, fullScreen: Bool) async {
        do {
            let content: SCShareableContent
            do {
                content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
            } catch {
                print("âŒ è·å–å…±äº«å†…å®¹å¤±è´¥: \(error)")
                return
            }

            guard content.displays.count >= 2 else {
                print("âŒ æ‰¾ä¸åˆ°ç¬¬äºŒä¸ªæ˜¾ç¤ºå™¨")
                return
            }
            let targetDisplay = content.displays[1]
            let display = targetDisplay

            let config = SCStreamConfiguration()
            
            // ä½¿ç”¨ä¸ .bak æ–‡ä»¶ç›¸åŒçš„æ–¹æ³•è·å–å±å¹•å°ºå¯¸
            // é€šè¿‡ NSScreen è·å–å®é™…åƒç´ å°ºå¯¸ï¼ˆè€ƒè™‘ Retina ç¼©æ”¾ï¼‰
            let screens = NSScreen.screens
            guard screens.count >= 2 else {
                print("âŒ NSScreen æ‰¾ä¸åˆ°ç¬¬äºŒä¸ªæ˜¾ç¤ºå™¨")
                return
            }
            let screen1 = screens[1]
            let scaleFactor = screen1.backingScaleFactor
            let logicalWidth = Int(screen1.frame.width)
            let logicalHeight = Int(screen1.frame.height)
            let actualWidth = Int(Double(logicalWidth) * scaleFactor)
            let actualHeight = Int(Double(logicalHeight) * scaleFactor)
            
            print("ğŸ–¥ï¸ æ˜¾ç¤ºå™¨ä¿¡æ¯:")
            print("   NSScreen é€»è¾‘å°ºå¯¸: \(logicalWidth) Ã— \(logicalHeight)")
            print("   ç¼©æ”¾å› å­: \(scaleFactor)")
            print("   å®é™…åƒç´ å°ºå¯¸: \(actualWidth) Ã— \(actualHeight)")
            print("   ScreenCaptureKit å°ºå¯¸: \(display.width) Ã— \(display.height)")
            
            let captureWidth: Int
            let captureHeight: Int
            let sourceRect: CGRect
            
            if fullScreen {
                // æ•´å±å½•åˆ¶
                captureWidth = actualWidth
                captureHeight = actualHeight
                // sourceRect ä½¿ç”¨é€»è¾‘åæ ‡
                sourceRect = CGRect(x: 0, y: 0, width: logicalWidth, height: logicalHeight)
            } else {
                // 3:4 ç«–å±æ¯”ä¾‹è£å‰ªï¼Œä»å·¦ä¸Šè§’å¼€å§‹æˆªå–
                captureHeight = actualHeight
                captureWidth = actualHeight * 3 / 4
                // sourceRect ä½¿ç”¨é€»è¾‘åæ ‡ï¼Œä½†ä¿æŒ 3:4 æ¯”ä¾‹
                let logicalCropWidth = logicalHeight * 3 / 4
                sourceRect = CGRect(x: 0, y: 0, width: logicalCropWidth, height: logicalHeight)
            }
            
            config.sourceRect = sourceRect
            config.width = captureWidth
            config.height = captureHeight
            
            print("ğŸ“¹ å½•åˆ¶é…ç½®:")
            print("   æºåŒºåŸŸï¼ˆé€»è¾‘åæ ‡ï¼‰: \(sourceRect)")
            print("   è¾“å‡ºå°ºå¯¸ï¼ˆå®é™…åƒç´ ï¼‰: \(captureWidth) Ã— \(captureHeight)")
            config.pixelFormat = kCVPixelFormatType_32BGRA
            config.minimumFrameInterval = CMTime(value: 1, timescale: 60)
            
            // å…³é”®ï¼šç¡®ä¿æ•è·é«˜åˆ†è¾¨ç‡å†…å®¹
            config.scalesToFit = false  // ä¸è¦ç¼©æ”¾ä»¥é€‚åº”
            
            // æé«˜è´¨é‡è®¾ç½®
            if #available(macOS 14.0, *) {
                config.queueDepth = 8
            }
            config.colorSpaceName = CGColorSpace.displayP3
            config.backgroundColor = CGColor.clear
            config.showsCursor = false
            
            print("ğŸ“¹ å½•åˆ¶é…ç½®:")
            print("   æºåŒºåŸŸï¼ˆé€»è¾‘åæ ‡ï¼‰: \(sourceRect)")
            print("   è¾“å‡ºå°ºå¯¸ï¼ˆå®é™…åƒç´ ï¼‰: \(captureWidth) Ã— \(captureHeight)")
            print("   scalesToFit: \(config.scalesToFit)")

            if #available(macOS 13.0, *) {
                config.capturesAudio = true
            }

            // è®¾ç½®è¾“å‡ºè·¯å¾„
            let outputURL: URL
            if let path = outputPath, !path.isEmpty {
                outputURL = URL(fileURLWithPath: path)
            } else {
                outputURL = URL(fileURLWithPath: FileManager.default.currentDirectoryPath)
                    .appendingPathComponent("screenRecording.mov")
            }

            if FileManager.default.fileExists(atPath: outputURL.path) {
                try FileManager.default.removeItem(at: outputURL)
            }

            let writer: AVAssetWriter
            do {
                writer = try AVAssetWriter(outputURL: outputURL, fileType: .mov)
            } catch {
                print("âŒ åˆ›å»º AVAssetWriter å¤±è´¥: \(error)")
                return
            }
            
            // ä½¿ç”¨æ›´é«˜è´¨é‡çš„è§†é¢‘è®¾ç½®
            let settings: [String: Any] = [
                AVVideoCodecKey: AVVideoCodecType.h264,
                AVVideoWidthKey: captureWidth,
                AVVideoHeightKey: captureHeight,
                AVVideoCompressionPropertiesKey: [
                    AVVideoAverageBitRateKey: captureWidth * captureHeight * 4, // é«˜æ¯”ç‰¹ç‡
                    AVVideoProfileLevelKey: AVVideoProfileLevelH264HighAutoLevel,
                    AVVideoH264EntropyModeKey: AVVideoH264EntropyModeCABAC,
                    AVVideoExpectedSourceFrameRateKey: 60,
                    AVVideoMaxKeyFrameIntervalKey: 60
                ]
            ]
            let input = AVAssetWriterInput(mediaType: .video, outputSettings: settings)
            input.expectsMediaDataInRealTime = true

            let audioSettings: [String: Any] = [
                AVFormatIDKey: kAudioFormatMPEG4AAC,
                AVNumberOfChannelsKey: 2,
                AVSampleRateKey: 44100,
                AVEncoderBitRateKey: 192000
            ]
            let audioInput = AVAssetWriterInput(mediaType: .audio, outputSettings: audioSettings)
            audioInput.expectsMediaDataInRealTime = true
            writer.add(audioInput)

            // è®¾ç½®åƒç´ ç¼“å†²åŒºå±æ€§ä»¥åŒ¹é…æºæ ¼å¼
            let pixelBufferAttributes: [String: Any] = [
                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
                kCVPixelBufferWidthKey as String: captureWidth,
                kCVPixelBufferHeightKey as String: captureHeight,
                kCVPixelBufferIOSurfacePropertiesKey as String: [:]
            ]
            let adaptor = AVAssetWriterInputPixelBufferAdaptor(assetWriterInput: input, sourcePixelBufferAttributes: pixelBufferAttributes)
            writer.add(input)
            writer.startWriting()
            // ç§»é™¤ writer.startSession(atSourceTime: .zero)

            class Delegate: NSObject, SCStreamOutput {
                let input: AVAssetWriterInput
                let audioInput: AVAssetWriterInput
                let adaptor: AVAssetWriterInputPixelBufferAdaptor
                var startTime: CMTime?
                let writer: AVAssetWriter

                init(input: AVAssetWriterInput, audioInput: AVAssetWriterInput, adaptor: AVAssetWriterInputPixelBufferAdaptor, writer: AVAssetWriter) {
                    self.input = input
                    self.audioInput = audioInput
                    self.adaptor = adaptor
                    self.writer = writer
                }

                func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of outputType: SCStreamOutputType) {
                    let timestamp = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
                    if startTime == nil {
                        startTime = timestamp
                        writer.startSession(atSourceTime: startTime!)
                    }

                    switch outputType {
                    case .screen:
                        guard let pixelBuffer = sampleBuffer.imageBuffer else { return }
                        if input.isReadyForMoreMediaData {
                            adaptor.append(pixelBuffer, withPresentationTime: timestamp)
                        }
                    case .audio:
                        if audioInput.isReadyForMoreMediaData {
                            audioInput.append(sampleBuffer)
                        }
                    default:
                        break
                    }
                }
            }

            let delegate = Delegate(input: input, audioInput: audioInput, adaptor: adaptor, writer: writer)

            let stream = SCStream(
                filter: SCContentFilter(display: display, excludingWindows: []),
                configuration: config,
                delegate: nil
            )

            // ä½¿ç”¨ä¸“ç”¨çš„é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—å¤„ç†è§†é¢‘æ•°æ®
            let videoQueue = DispatchQueue(label: "videoQueue", qos: .userInitiated)
            let audioQueue = DispatchQueue(label: "audioQueue", qos: .userInitiated)
            
            do {
                try stream.addStreamOutput(delegate, type: .screen, sampleHandlerQueue: videoQueue)
            } catch {
                print("âŒ æ·»åŠ è§†é¢‘æµè¾“å‡ºå¤±è´¥: \(error)")
                return
            }

            do {
                if #available(macOS 13.0, *) {
                    try stream.addStreamOutput(delegate, type: SCStreamOutputType.audio, sampleHandlerQueue: audioQueue)
                }
            } catch {
                print("âŒ æ·»åŠ éŸ³é¢‘æµè¾“å‡ºå¤±è´¥: \(error)")
                return
            }

            do {
                try await stream.startCapture()
            } catch {
                print("âŒ å¯åŠ¨å½•åˆ¶å¤±è´¥: \(error)")
                return
            }

            // å½•åˆ¶å‰åˆ‡æ¢éŸ³é¢‘è¾“å‡ºåˆ° BlackHole
            // switchAudioOutput(to: "BlackHole 16ch")
            
            let durationSec = Double(durationMs) / 1000.0
            print("âœ… å¼€å§‹å½•åˆ¶ï¼ˆ\(durationSec) ç§’ï¼‰...")
            try await Task.sleep(nanoseconds: UInt64(durationMs * 1_000_000))

            print("ğŸ›‘ åœæ­¢å½•åˆ¶...")
            do {
                try await stream.stopCapture()
            } catch {
                print("âŒ åœæ­¢å½•åˆ¶å¤±è´¥: \(error)")
            }
            input.markAsFinished()
            audioInput.markAsFinished()

            // ç”¨å¼‚æ­¥æ–¹å¼ç­‰å¾…å†™å…¥å®Œæˆ
            try await withCheckedThrowingContinuation { continuation in
                writer.finishWriting {
                    if writer.status == .completed {
                        print("ğŸ¬ å·²ä¿å­˜è§†é¢‘: \(outputURL.path)")
                        // å½•åˆ¶å®Œæˆååˆ‡æ¢å›é»˜è®¤éŸ³é¢‘è®¾å¤‡
                        // switchAudioOutput(to: "MacBook Pro Speakers")
                        continuation.resume()
                    } else if let error = writer.error {
                        // å‡ºé”™æ—¶ä¹Ÿè¦åˆ‡æ¢å›é»˜è®¤éŸ³é¢‘è®¾å¤‡
                        // switchAudioOutput(to: "MacBook Pro Speakers")
                        continuation.resume(throwing: error)
                    } else {
                        // switchAudioOutput(to: "MacBook Pro Speakers")
                        continuation.resume(throwing: NSError(domain: "com.screenrecorder", code: -1, userInfo: [NSLocalizedDescriptionKey: "æœªçŸ¥å†™å…¥é”™è¯¯"]))
                    }
                }
            }

        } catch {
            print("âš ï¸ å½•åˆ¶å¤±è´¥ï¼š\(error)")
            // å‡ºé”™æ—¶ä¹Ÿè¦åˆ‡æ¢å›é»˜è®¤éŸ³é¢‘è®¾å¤‡
            // switchAudioOutput(to: "MacBook Pro Speakers")
            exit(EXIT_FAILURE)
        }
    }
}