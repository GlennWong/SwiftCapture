import Foundation
import ScreenCaptureKit
@preconcurrency import AVFoundation
import AppKit
import CoreGraphics

/// Controls the actual screen capture process using ScreenCaptureKit
/// Provides modular recording functionality with proper error handling
@available(macOS 12.3, *)
class CaptureController {
    
    private var currentDelegate: CaptureDelegate?
    private var currentStream: SCStream?
    private var isStreamStopped = false
    
    /// Error types for capture operations
    enum CaptureError: LocalizedError {
        case contentRetrievalFailed(Error)
        case streamCreationFailed(Error)
        case captureStartFailed(Error)
        case captureStopFailed(Error)
        case configurationError(String)
        
        var errorDescription: String? {
            switch self {
            case .contentRetrievalFailed(let error):
                return "Failed to retrieve shareable content: \(error.localizedDescription)"
            case .streamCreationFailed(let error):
                return "Failed to create capture stream: \(error.localizedDescription)"
            case .captureStartFailed(let error):
                return "Failed to start capture: \(error.localizedDescription)"
            case .captureStopFailed(let error):
                return "Failed to stop capture: \(error.localizedDescription)"
            case .configurationError(let message):
                return "Configuration error: \(message)"
            }
        }
    }
    
    /// Delegate for handling capture output
    private class CaptureDelegate: NSObject, SCStreamOutput {
        let videoInput: AVAssetWriterInput
        let audioInput: AVAssetWriterInput?
        let adaptor: AVAssetWriterInputPixelBufferAdaptor
        let writer: AVAssetWriter
        private var startTime: CMTime?
        private var shouldStop = false
        private var frameCount = 0
        private var audioSampleCount = 0
        
        // éº¦å…‹é£å½•åˆ¶ç›¸å…³
        private var audioEngine: AVAudioEngine?
        private var microphoneInput: AVAssetWriterInput?
        private var audioMixer: AVAudioMixerNode?
        private let includeMicrophone: Bool
        
        init(videoInput: AVAssetWriterInput, 
             audioInput: AVAssetWriterInput?, 
             adaptor: AVAssetWriterInputPixelBufferAdaptor, 
             writer: AVAssetWriter,
             includeMicrophone: Bool = false) {
            self.videoInput = videoInput
            self.audioInput = audioInput
            self.adaptor = adaptor
            self.writer = writer
            self.includeMicrophone = includeMicrophone
            
            super.init()
            
            // å¦‚æœéœ€è¦éº¦å…‹é£ï¼Œè®¾ç½®éŸ³é¢‘å¼•æ“
            if includeMicrophone {
                setupMicrophoneRecording()
            }
        }
        
        private func setupMicrophoneRecording() {
            do {
                audioEngine = AVAudioEngine()
                guard let audioEngine = audioEngine else { return }
                
                let inputNode = audioEngine.inputNode
                let recordingFormat = inputNode.outputFormat(forBus: 0)
                
                // åˆ›å»ºæ··éŸ³å™¨èŠ‚ç‚¹
                audioMixer = AVAudioMixerNode()
                guard let audioMixer = audioMixer else { return }
                
                audioEngine.attach(audioMixer)
                audioEngine.connect(inputNode, to: audioMixer, format: recordingFormat)
                audioEngine.connect(audioMixer, to: audioEngine.outputNode, format: recordingFormat)
                
                // å®‰è£…éŸ³é¢‘å¤„ç†å›è°ƒ
                audioMixer.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, time in
                    self?.processMicrophoneAudio(buffer: buffer, time: time)
                }
                
                try audioEngine.start()
                print("ğŸ¤ Microphone audio engine started successfully")
                
            } catch {
                print("âš ï¸ Failed to setup microphone recording: \(error.localizedDescription)")
                audioEngine = nil
                audioMixer = nil
            }
        }
        
        private func processMicrophoneAudio(buffer: AVAudioPCMBuffer, time: AVAudioTime) {
            // æš‚æ—¶åªè®°å½•éº¦å…‹é£éŸ³é¢‘å¤„ç†ï¼Œé¿å…å¹²æ‰°ç³»ç»ŸéŸ³é¢‘å½•åˆ¶
            // å®é™…çš„éŸ³é¢‘æ··åˆéœ€è¦æ›´å¤æ‚çš„å®ç°
            if frameCount % 1000 == 0 { // å‡å°‘æ—¥å¿—é¢‘ç‡
                print("ğŸ¤ Microphone audio detected (not yet mixed)")
            }
        }
        
        func stopCapture() {
            shouldStop = true
            
            // åœæ­¢éº¦å…‹é£å½•åˆ¶
            if let audioEngine = audioEngine {
                audioMixer?.removeTap(onBus: 0)
                audioEngine.stop()
                print("ğŸ¤ Microphone audio engine stopped")
            }
        }
        
        func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of outputType: SCStreamOutputType) {
            // Stop processing if we've been told to stop
            if shouldStop {
                return
            }
            
            let timestamp = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
            
            // Initialize session timing on first frame
            if startTime == nil {
                startTime = timestamp
                writer.startSession(atSourceTime: startTime!)
            }
            
            // Don't check duration here - let the main recording loop handle timing
            
            switch outputType {
            case .screen:
                guard let pixelBuffer = sampleBuffer.imageBuffer else { return }
                

                
                if videoInput.isReadyForMoreMediaData && !shouldStop {
                    let success = adaptor.append(pixelBuffer, withPresentationTime: timestamp)
                    frameCount += 1
                    if !success {
                        print("âš ï¸ Failed to append video frame at timestamp: \(CMTimeGetSeconds(timestamp))")
                        print("   Frame count: \(frameCount), Video input ready: \(videoInput.isReadyForMoreMediaData)")
                    } else if frameCount % 600 == 0 { // Log every 600 frames (20 seconds at 30fps)
                        print("ğŸ“¹ Video frames processed: \(frameCount) (timestamp: \(String(format: "%.2f", CMTimeGetSeconds(timestamp)))s)")
                    }
                }
            case .audio:
                if let audioInput = audioInput, audioInput.isReadyForMoreMediaData && !shouldStop {
                    let success = audioInput.append(sampleBuffer)
                    audioSampleCount += 1
                    if !success {
                        print("âš ï¸ Failed to append audio sample at timestamp: \(CMTimeGetSeconds(timestamp))")
                        print("   Audio samples: \(audioSampleCount), Audio input ready: \(audioInput.isReadyForMoreMediaData)")
                    } else if audioSampleCount % 1000 == 0 { // Log every 1000 audio samples
                        print("ğŸµ Audio samples processed: \(audioSampleCount) (timestamp: \(String(format: "%.2f", CMTimeGetSeconds(timestamp)))s)")
                    }
                }
            default:
                break
            }
        }
    }
    
    /// Start screen capture with the given configuration
    /// - Parameters:
    ///   - config: Recording configuration
    ///   - writer: AVAssetWriter for output
    ///   - videoInput: Video input for the writer
    ///   - audioInput: Optional audio input for the writer
    ///   - adaptor: Pixel buffer adaptor for video
    /// - Returns: SCStream instance for the capture
    /// - Throws: CaptureError if capture setup fails
    func startCapture(
        with config: RecordingConfiguration,
        writer: AVAssetWriter,
        videoInput: AVAssetWriterInput,
        audioInput: AVAssetWriterInput?,
        adaptor: AVAssetWriterInputPixelBufferAdaptor
    ) async throws -> SCStream {
        
        // ğŸ”§ ä¿®å¤ï¼šå¯¹äºåº”ç”¨å½•åˆ¶ï¼Œå…ˆå°†åº”ç”¨ç½®äºå‰å°
        if config.recordingMode == .application, let targetApp = config.targetApplication {
            do {
                let appManager = ApplicationManager()
                try appManager.bringApplicationToFront(targetApp)
                
                // ç»™ç³»ç»Ÿæ›´å¤šæ—¶é—´æ¥å®Œæˆçª—å£åˆ‡æ¢å’Œæ¡Œé¢ç©ºé—´åˆ‡æ¢
                try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’
                
                print("   Waiting for application to be fully visible...")
            } catch {
                print("âš ï¸ Warning: Could not bring application to front: \(error.localizedDescription)")
                print("   Recording will continue, but the application may be obscured")
            }
        }
        
        // Get shareable content
        let content: SCShareableContent
        do {
            content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
        } catch {
            throw CaptureError.contentRetrievalFailed(error)
        }
        
        // Create stream configuration
        let streamConfig = try createStreamConfiguration(from: config, content: content)
        
        // Create content filter
        let filter = try createContentFilter(from: config, content: content)
        
        // Create capture delegate
        let delegate = CaptureDelegate(
            videoInput: videoInput,
            audioInput: audioInput,
            adaptor: adaptor,
            writer: writer,
            includeMicrophone: config.audioSettings.includeMicrophone
        )
        
        // Store delegate reference for later use
        self.currentDelegate = delegate
        
        // Create stream
        let stream = SCStream(filter: filter, configuration: streamConfig, delegate: nil)
        
        // Store stream reference and reset stopped flag
        self.currentStream = stream
        self.isStreamStopped = false
        
        // Add stream outputs
        let videoQueue = DispatchQueue(label: "videoQueue", qos: .userInitiated)
        let audioQueue = DispatchQueue(label: "audioQueue", qos: .userInitiated)
        
        do {
            try stream.addStreamOutput(delegate, type: .screen, sampleHandlerQueue: videoQueue)
        } catch {
            throw CaptureError.captureStartFailed(error)
        }
        
        // Add audio output if enabled
        if config.audioSettings.hasAudio {
            do {
                if #available(macOS 13.0, *) {
                    try stream.addStreamOutput(delegate, type: .audio, sampleHandlerQueue: audioQueue)
                    if config.verbose {
                        print("âœ… System audio stream added successfully")
                    }
                }
            } catch {
                print("âš ï¸ Warning: Failed to add system audio output: \(error.localizedDescription)")
                // Continue without system audio rather than failing completely
            }
        }
        
        // ğŸ”§ æ–°å¢ï¼šå¦‚æœå¯ç”¨äº†éº¦å…‹é£ï¼Œéœ€è¦å•ç‹¬å¤„ç†éº¦å…‹é£éŸ³é¢‘
        if config.audioSettings.includeMicrophone {
            print("ğŸ¤ Microphone recording enabled - will be mixed with system audio")
            // æ³¨æ„ï¼šScreenCaptureKit ä¸»è¦å¤„ç†ç³»ç»ŸéŸ³é¢‘ï¼Œéº¦å…‹é£éŸ³é¢‘éœ€è¦é€šè¿‡ AVAudioEngine å•ç‹¬å¤„ç†
            // è¿™éœ€è¦åœ¨ OutputManager ä¸­å®ç°éŸ³é¢‘æ··åˆé€»è¾‘
        }
        
        // Start capture
        do {
            try await stream.startCapture()
        } catch {
            throw CaptureError.captureStartFailed(error)
        }
        
        return stream
    }
    
    /// Stop screen capture
    /// - Parameter stream: SCStream to stop
    /// - Throws: CaptureError if stop fails
    func stopCapture(_ stream: SCStream) async throws {
        // Check if this stream has already been stopped
        guard !isStreamStopped else {
            print("â„¹ï¸ Stream stop already in progress or completed, skipping...")
            return
        }
        
        // Mark as stopped to prevent concurrent stop attempts
        isStreamStopped = true
        
        // First tell the delegate to stop processing new frames
        currentDelegate?.stopCapture()
        
        do {
            try await stream.stopCapture()
        } catch {
            // Check if the error is about stopping an already stopped stream
            let nsError = error as NSError
            if nsError.domain == "com.apple.ScreenCaptureKit.SCStreamErrorDomain" && nsError.code == -3808 {
                // Stream is already stopped, this is not an error in our context
                print("â„¹ï¸ Stream was already stopped, continuing cleanup...")
            } else {
                throw CaptureError.captureStopFailed(error)
            }
        }
        
        // Clear references
        currentDelegate = nil
        currentStream = nil
    }
    
    /// Create ScreenCaptureKit stream configuration from recording configuration
    /// - Parameters:
    ///   - config: Recording configuration
    ///   - content: Shareable content for validation
    /// - Returns: Configured SCStreamConfiguration
    /// - Throws: CaptureError if configuration is invalid
    private func createStreamConfiguration(
        from config: RecordingConfiguration, 
        content: SCShareableContent
    ) throws -> SCStreamConfiguration {
        
        let streamConfig = SCStreamConfiguration()
        
        // Configure recording area and resolution
        let (sourceRect, outputSize) = try calculateRecordingDimensions(
            config: config, 
            content: content
        )
        
        streamConfig.sourceRect = sourceRect
        streamConfig.width = Int(outputSize.width)
        streamConfig.height = Int(outputSize.height)
        
        // Configure video settings
        streamConfig.pixelFormat = kCVPixelFormatType_32BGRA
        streamConfig.minimumFrameInterval = config.videoSettings.frameInterval
        streamConfig.showsCursor = config.videoSettings.showCursor
        
        // ğŸ”§ ä¿®å¤ï¼šå¯¹äºåº”ç”¨å½•åˆ¶çš„ç‰¹æ®Šé…ç½®
        if config.recordingMode == .application {
            // åº”ç”¨å½•åˆ¶æ—¶çš„å…³é”®è®¾ç½®
            streamConfig.scalesToFit = false  // ç¦ç”¨è‡ªåŠ¨ç¼©æ”¾
            
            // ç‰ˆæœ¬å…¼å®¹çš„è®¾ç½®
            if #available(macOS 14.0, *) {
                streamConfig.preservesAspectRatio = true  // ä¿æŒå®½é«˜æ¯”
                streamConfig.captureResolution = .best
            }
            
            // å¯¹äºåº”ç”¨å½•åˆ¶ï¼Œä¸è®¾ç½®sourceRectï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨å¤„ç†
            if sourceRect == CGRect.null {
                // ä¸è®¾ç½®sourceRectï¼Œä½¿ç”¨å®Œæ•´çª—å£
                print("   Using full window capture (no sourceRect)")
            }
        } else {
            // å±å¹•å½•åˆ¶æ—¶ä¿æŒåŸæœ‰è®¾ç½®
            streamConfig.scalesToFit = false
        }
        
        // Configure color space and quality
        streamConfig.colorSpaceName = CGColorSpace.displayP3
        streamConfig.backgroundColor = CGColor.clear
        
        // Configure advanced settings for macOS 14+
        if #available(macOS 14.0, *) {
            streamConfig.queueDepth = 8
        }
        
        // Configure audio if enabled
        if config.audioSettings.hasAudio {
            if #available(macOS 13.0, *) {
                streamConfig.capturesAudio = true
            }
        }
        
        // Log capture configuration only in verbose mode
        if config.verbose {
            print("ğŸ“¹ Capture Configuration:")
            print("   Recording Mode: \(config.recordingMode)")
            if let screen = config.targetScreen {
                print("   Target Screen: \(screen.index) (\(screen.name))")
                print("   Screen Frame: \(screen.frame)")
                print("   Scale Factor: \(screen.scaleFactor)x")
            }
            print("   Source Rect: \(sourceRect)")
            print("   Output Size: \(Int(outputSize.width)) Ã— \(Int(outputSize.height))")
            print("   Frame Rate: \(config.videoSettings.fps) fps")
            print("   Show Cursor: \(config.videoSettings.showCursor)")
            print("   Audio Enabled: \(config.audioSettings.hasAudio)")
        }
        return streamConfig
    }
    
    /// Create content filter based on recording configuration
    /// - Parameters:
    ///   - config: Recording configuration
    ///   - content: Shareable content
    /// - Returns: Configured SCContentFilter
    /// - Throws: CaptureError if filter creation fails
    private func createContentFilter(
        from config: RecordingConfiguration,
        content: SCShareableContent
    ) throws -> SCContentFilter {
        
        // ğŸ”§ æ™ºèƒ½æ··åˆæ¨¡å¼ï¼šå½“åº”ç”¨å½•åˆ¶éœ€è¦ç³»ç»ŸéŸ³é¢‘ä¸”ä¸åŒ…å«éº¦å…‹é£æ—¶ï¼Œåˆ‡æ¢åˆ°å±å¹•å½•åˆ¶æ¨¡å¼
        // å¦‚æœåŒæ—¶éœ€è¦éº¦å…‹é£ï¼Œä¿æŒåº”ç”¨å½•åˆ¶æ¨¡å¼å¹¶å°è¯•æ··åˆéŸ³é¢‘
        if config.recordingMode == .application && config.audioSettings.forceSystemAudio && !config.audioSettings.includeMicrophone {
            print("ğŸ”„ Smart Hybrid Mode: Switching to screen recording for system-wide audio")
            print("   Will record the screen area containing the application window")
            
            guard let targetApp = config.targetApplication else {
                throw CaptureError.configurationError("No target application specified")
            }
            
            // æ‰¾åˆ°åº”ç”¨çª—å£
            let appWindows = content.windows.filter { window in
                window.owningApplication?.bundleIdentifier == targetApp.bundleIdentifier
            }
            
            guard let appWindow = appWindows.first else {
                throw CaptureError.configurationError("No windows found for target application '\(targetApp.name)'")
            }
            
            // æ‰¾åˆ°åŒ…å«åº”ç”¨çª—å£çš„æ˜¾ç¤ºå™¨
            let windowCenter = CGPoint(
                x: appWindow.frame.origin.x + appWindow.frame.width / 2,
                y: appWindow.frame.origin.y + appWindow.frame.height / 2
            )
            
            var targetDisplay: SCDisplay?
            let screens = NSScreen.screens
            
            for screen in screens {
                if screen.frame.contains(windowCenter) {
                    let screenNumber = screen.deviceDescription[NSDeviceDescriptionKey("NSScreenNumber")] as? CGDirectDisplayID
                    targetDisplay = content.displays.first { $0.displayID == screenNumber }
                    break
                }
            }
            
            if targetDisplay == nil {
                targetDisplay = content.displays.first { $0.displayID == CGMainDisplayID() } ?? content.displays.first!
            }
            
            print("   Target Display: ID \(targetDisplay!.displayID)")
            print("   Window Area: \(Int(appWindow.frame.origin.x)), \(Int(appWindow.frame.origin.y)), \(Int(appWindow.frame.width)) Ã— \(Int(appWindow.frame.height))")
            
            return SCContentFilter(display: targetDisplay!, excludingWindows: [])
        }
        
        switch config.recordingMode {
        case .screen:
            // Screen recording mode
            let targetDisplay: SCDisplay
            
            if let screenInfo = config.targetScreen {
                // Find the display matching the screen info
                guard let display = content.displays.first(where: { $0.displayID == screenInfo.displayID }) else {
                    throw CaptureError.configurationError("Target screen not found in available displays")
                }
                targetDisplay = display
            } else {
                // Use primary display
                guard let display = content.displays.first else {
                    throw CaptureError.configurationError("No displays available for recording")
                }
                targetDisplay = display
            }
            
            return SCContentFilter(display: targetDisplay, excludingWindows: [])
            
        case .application:
            // Application recording mode
            guard let targetApp = config.targetApplication else {
                throw CaptureError.configurationError("No target application specified for application recording")
            }
            
            // Find the application in shareable content
            guard content.applications.contains(where: { 
                $0.bundleIdentifier == targetApp.bundleIdentifier 
            }) else {
                throw CaptureError.configurationError("Target application not found in shareable content")
            }
            
            // Get windows for the application
            let appWindows = content.windows.filter { window in
                window.owningApplication?.bundleIdentifier == targetApp.bundleIdentifier
            }
            
            if appWindows.isEmpty {
                throw CaptureError.configurationError("No windows found for target application '\(targetApp.name)'")
            }
            
            // ğŸ”§ ä¿®å¤ï¼šé€‰æ‹©æœ€ä½³çª—å£è¿›è¡Œå½•åˆ¶
            // ä¼˜å…ˆé€‰æ‹©æœ‰æ ‡é¢˜ä¸”å°ºå¯¸è¾ƒå¤§çš„çª—å£ï¼ˆé€šå¸¸æ˜¯ä¸»çª—å£ï¼‰
            let bestWindow = appWindows.max { lhs, rhs in
                // é¦–å…ˆæ¯”è¾ƒæ˜¯å¦æœ‰æ ‡é¢˜
                let lhsHasTitle = !(lhs.title?.isEmpty ?? true)
                let rhsHasTitle = !(rhs.title?.isEmpty ?? true)
                
                if lhsHasTitle != rhsHasTitle {
                    return rhsHasTitle // æœ‰æ ‡é¢˜çš„çª—å£ä¼˜å…ˆ
                }
                
                // å¦‚æœéƒ½æœ‰æ ‡é¢˜æˆ–éƒ½æ²¡æ ‡é¢˜ï¼Œæ¯”è¾ƒçª—å£é¢ç§¯
                let lhsArea = lhs.frame.width * lhs.frame.height
                let rhsArea = rhs.frame.width * rhs.frame.height
                return lhsArea < rhsArea // é¢ç§¯å¤§çš„çª—å£ä¼˜å…ˆ
            } ?? appWindows.first!
            
            print("ğŸ¯ Selected window for recording:")
            print("   Title: '\((bestWindow.title?.isEmpty ?? true) ? "Untitled" : bestWindow.title!)'")
            print("   Size: \(Int(bestWindow.frame.width)) Ã— \(Int(bestWindow.frame.height))")
            print("   Position: (\(Int(bestWindow.frame.origin.x)), \(Int(bestWindow.frame.origin.y)))")
            

            
            return SCContentFilter(desktopIndependentWindow: bestWindow)
        }
    }
    
    /// Calculate recording dimensions based on configuration
    /// - Parameters:
    ///   - config: Recording configuration
    ///   - content: Shareable content for screen information
    /// - Returns: Tuple of source rect and output size
    /// - Throws: CaptureError if calculation fails
    private func calculateRecordingDimensions(
        config: RecordingConfiguration,
        content: SCShareableContent
    ) throws -> (sourceRect: CGRect, outputSize: CGSize) {
        
        // ğŸ”§ å¤„ç†æ··åˆæ¨¡å¼ï¼šåº”ç”¨å½•åˆ¶ + ç³»ç»ŸéŸ³é¢‘ = å±å¹•å½•åˆ¶æ¨¡å¼ä½†ä½¿ç”¨åº”ç”¨çª—å£åŒºåŸŸ
        if config.recordingMode == .application && config.audioSettings.forceSystemAudio {
            return try calculateHybridRecordingDimensions(config: config, content: content)
        }
        
        switch config.recordingMode {
        case .screen:
            return try calculateScreenRecordingDimensions(config: config, content: content)
        case .application:
            return try calculateApplicationRecordingDimensions(config: config, content: content)
        }
    }
    
    /// Calculate dimensions for screen recording
    private func calculateScreenRecordingDimensions(
        config: RecordingConfiguration,
        content: SCShareableContent
    ) throws -> (sourceRect: CGRect, outputSize: CGSize) {
        
        let targetDisplay: SCDisplay
        
        if let screenInfo = config.targetScreen {
            guard let display = content.displays.first(where: { $0.displayID == screenInfo.displayID }) else {
                throw CaptureError.configurationError("Target screen not found")
            }
            targetDisplay = display
        } else {
            guard let display = content.displays.first else {
                throw CaptureError.configurationError("No displays available")
            }
            targetDisplay = display
        }
        
        // Get screen information from NSScreen for scale factor
        let screens = NSScreen.screens
        guard let nsScreen = screens.first(where: { 
            $0.deviceDescription[NSDeviceDescriptionKey("NSScreenNumber")] as? CGDirectDisplayID == targetDisplay.displayID 
        }) else {
            throw CaptureError.configurationError("Could not find NSScreen for display")
        }
        
        let scaleFactor = nsScreen.backingScaleFactor
        let logicalFrame = nsScreen.frame
        
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å±å¹•æœ¬åœ°åæ ‡ç³»è®¡ç®—å½•åˆ¶åŒºåŸŸ
        let screenInfo = ScreenInfo(
            index: 1,
            displayID: targetDisplay.displayID,
            frame: logicalFrame,
            name: "Display",
            isPrimary: true,
            scaleFactor: scaleFactor
        )
        
        // è·å–å½•åˆ¶åŒºåŸŸï¼ˆåƒç´ åæ ‡ï¼‰
        let recordingRect = config.recordingArea.toCGRect(for: screenInfo)
        let actualWidth = Int(recordingRect.width)
        let actualHeight = Int(recordingRect.height)
        
        // ğŸ”§ å…³é”®ä¿®å¤ï¼šå¯¹äºScreenCaptureKitï¼Œä½¿ç”¨å±å¹•æœ¬åœ°é€»è¾‘åæ ‡
        // ä¸éœ€è¦è€ƒè™‘å±å¹•åœ¨å…¨å±€åæ ‡ç³»ä¸­çš„åç§»
        let logicalSourceRect = config.recordingArea.toLogicalRect(for: screenInfo)
        
        return (
            sourceRect: logicalSourceRect,
            outputSize: CGSize(width: actualWidth, height: actualHeight)
        )
    }
    
    /// Calculate dimensions for application recording
    private func calculateApplicationRecordingDimensions(
        config: RecordingConfiguration,
        content: SCShareableContent
    ) throws -> (sourceRect: CGRect, outputSize: CGSize) {
        
        guard let targetApp = config.targetApplication else {
            throw CaptureError.configurationError("No target application specified")
        }
        
        // Find application windows in ScreenCaptureKit content
        let appWindows = content.windows.filter { window in
            window.owningApplication?.bundleIdentifier == targetApp.bundleIdentifier
        }
        
        guard !appWindows.isEmpty else {
            throw CaptureError.configurationError("No windows found for target application '\(targetApp.name)'")
        }
        
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸å†…å®¹è¿‡æ»¤å™¨ç›¸åŒçš„çª—å£é€‰æ‹©é€»è¾‘
        let scWindow = appWindows.max { lhs, rhs in
            // é¦–å…ˆæ¯”è¾ƒæ˜¯å¦æœ‰æ ‡é¢˜
            let lhsHasTitle = !(lhs.title?.isEmpty ?? true)
            let rhsHasTitle = !(rhs.title?.isEmpty ?? true)
            
            if lhsHasTitle != rhsHasTitle {
                return rhsHasTitle // æœ‰æ ‡é¢˜çš„çª—å£ä¼˜å…ˆ
            }
            
            // å¦‚æœéƒ½æœ‰æ ‡é¢˜æˆ–éƒ½æ²¡æ ‡é¢˜ï¼Œæ¯”è¾ƒçª—å£é¢ç§¯
            let lhsArea = lhs.frame.width * lhs.frame.height
            let rhsArea = rhs.frame.width * rhs.frame.height
            return lhsArea < rhsArea // é¢ç§¯å¤§çš„çª—å£ä¼˜å…ˆ
        } ?? appWindows.first!
        
        // Get the ScreenCaptureKit window frame (this is already in the correct coordinate system)
        let scWindowFrame = scWindow.frame
        
        // Find the display that contains this window to get the correct scale factor
        let windowCenter = CGPoint(
            x: scWindowFrame.origin.x + scWindowFrame.width / 2,
            y: scWindowFrame.origin.y + scWindowFrame.height / 2
        )
        
        // Get the display containing the window center
        let screens = NSScreen.screens
        var scaleFactor: CGFloat = 1.0
        var containingScreen: NSScreen?
        
        for screen in screens {
            // Convert screen frame to match ScreenCaptureKit coordinate system
            let screenFrame = screen.frame
            let flippedScreenFrame = CGRect(
                x: screenFrame.origin.x,
                y: screenFrame.origin.y,
                width: screenFrame.width,
                height: screenFrame.height
            )
            
            if flippedScreenFrame.contains(windowCenter) {
                scaleFactor = screen.backingScaleFactor
                containingScreen = screen
                break
            }
        }
        
        // If no screen contains the window center, use the main screen's scale factor
        if scaleFactor == 1.0 {
            scaleFactor = NSScreen.main?.backingScaleFactor ?? 1.0
            containingScreen = NSScreen.main
        }
        
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ScreenCaptureKitçª—å£çš„å®é™…å°ºå¯¸
        // ScreenCaptureKitå·²ç»æä¾›äº†æ­£ç¡®çš„çª—å£è¾¹ç•Œï¼Œä¸éœ€è¦é¢å¤–çš„åæ ‡è½¬æ¢
        let actualWidth = scWindowFrame.width
        let actualHeight = scWindowFrame.height
        
        // è®¡ç®—è¾“å‡ºåƒç´ å°ºå¯¸ - ä½¿ç”¨å®é™…çª—å£å°ºå¯¸ä¹˜ä»¥ç¼©æ”¾å› å­
        let outputWidth = Int(actualWidth * scaleFactor)
        let outputHeight = Int(actualHeight * scaleFactor)
        
        print("ğŸ” Application Recording Debug:")
        print("   Found \(appWindows.count) windows for '\(targetApp.name)'")
        for (index, window) in appWindows.enumerated() {
            let title = (window.title?.isEmpty ?? true) ? "Untitled" : window.title!
            print("     \(index + 1). '\(title)' - \(Int(window.frame.width))Ã—\(Int(window.frame.height))")
        }
        print("   Selected Window: '\((scWindow.title?.isEmpty ?? true) ? "Untitled" : scWindow.title!)'")
        print("   SCWindow Frame: \(Int(scWindowFrame.origin.x)), \(Int(scWindowFrame.origin.y)), \(Int(actualWidth)) Ã— \(Int(actualHeight))")
        print("   Scale Factor: \(scaleFactor)x")
        print("   Output Size (pixels): \(outputWidth) Ã— \(outputHeight)")
        print("   Containing Screen: \(containingScreen?.localizedName ?? "Unknown")")
        
        // ğŸ”§ å…³é”®ä¿®å¤ï¼šä¸ä½¿ç”¨sourceRectï¼Œè®©ScreenCaptureKitè‡ªåŠ¨å¤„ç†çª—å£è¾¹ç•Œ
        // å¯¹äºåº”ç”¨çª—å£å½•åˆ¶ï¼ŒsourceRectåº”è¯¥è®¾ç½®ä¸ºCGRect.nullæˆ–çª—å£çš„å®Œæ•´åŒºåŸŸ
        return (
            sourceRect: CGRect.null, // è®©ScreenCaptureKitè‡ªåŠ¨ä½¿ç”¨å®Œæ•´çª—å£åŒºåŸŸ
            outputSize: CGSize(width: outputWidth, height: outputHeight)
        )
    }
    
    /// Calculate dimensions for hybrid recording (app window area on screen for system audio)
    private func calculateHybridRecordingDimensions(
        config: RecordingConfiguration,
        content: SCShareableContent
    ) throws -> (sourceRect: CGRect, outputSize: CGSize) {
        
        guard let targetApp = config.targetApplication else {
            throw CaptureError.configurationError("No target application specified")
        }
        
        // æ‰¾åˆ°åº”ç”¨çª—å£
        let appWindows = content.windows.filter { window in
            window.owningApplication?.bundleIdentifier == targetApp.bundleIdentifier
        }
        
        guard let appWindow = appWindows.first else {
            throw CaptureError.configurationError("No windows found for target application '\(targetApp.name)'")
        }
        
        // è·å–çª—å£æ‰€åœ¨çš„å±å¹•ä¿¡æ¯
        let windowCenter = CGPoint(
            x: appWindow.frame.origin.x + appWindow.frame.width / 2,
            y: appWindow.frame.origin.y + appWindow.frame.height / 2
        )
        
        let screens = NSScreen.screens
        var scaleFactor: CGFloat = 1.0
        var containingScreen: NSScreen?
        
        for screen in screens {
            if screen.frame.contains(windowCenter) {
                scaleFactor = screen.backingScaleFactor
                containingScreen = screen
                break
            }
        }
        
        if scaleFactor == 1.0 {
            scaleFactor = NSScreen.main?.backingScaleFactor ?? 1.0
            containingScreen = NSScreen.main
        }
        
        // ğŸ”§ æ··åˆæ¨¡å¼ï¼šä½¿ç”¨å±å¹•å½•åˆ¶ä½†é™åˆ¶åœ¨åº”ç”¨çª—å£åŒºåŸŸ
        let windowFrame = appWindow.frame
        let actualWidth = windowFrame.width
        let actualHeight = windowFrame.height
        
        // è®¡ç®—è¾“å‡ºåƒç´ å°ºå¯¸
        let outputWidth = Int(actualWidth * scaleFactor)
        let outputHeight = Int(actualHeight * scaleFactor)
        
        // ğŸ”§ å…³é”®ï¼šè®¾ç½® sourceRect ä¸ºåº”ç”¨çª—å£åœ¨å±å¹•ä¸Šçš„ä½ç½®ï¼ˆé€»è¾‘åæ ‡ï¼‰
        // è¿™æ ·å±å¹•å½•åˆ¶æ¨¡å¼åªä¼šå½•åˆ¶çª—å£åŒºåŸŸï¼ŒåŒæ—¶è·å¾—ç³»ç»ŸéŸ³é¢‘
        let sourceRect = CGRect(
            x: windowFrame.origin.x,
            y: windowFrame.origin.y,
            width: actualWidth,
            height: actualHeight
        )
        
        print("ğŸ” Hybrid Recording Debug:")
        print("   Window Frame: \(Int(windowFrame.origin.x)), \(Int(windowFrame.origin.y)), \(Int(actualWidth)) Ã— \(Int(actualHeight))")
        print("   Scale Factor: \(scaleFactor)x")
        print("   Source Rect (logical): \(Int(sourceRect.origin.x)), \(Int(sourceRect.origin.y)), \(Int(sourceRect.width)) Ã— \(Int(sourceRect.height))")
        print("   Output Size (pixels): \(outputWidth) Ã— \(outputHeight)")
        print("   Containing Screen: \(containingScreen?.localizedName ?? "Unknown")")
        
        return (
            sourceRect: sourceRect,
            outputSize: CGSize(width: outputWidth, height: outputHeight)
        )
    }
}